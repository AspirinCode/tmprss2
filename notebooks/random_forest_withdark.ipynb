{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#load data labels and RDkit fingerprints\n",
    "#naively assign data for all proteins to one giant array\n",
    "f_truth = pd.read_pickle('../processed_data/TMPRSS2_processed.pkl')\n",
    "f_tmpss11d = pd.read_pickle('../processed_data/TMPRSS11D_processed.pkl')\n",
    "f_st14 = pd.read_pickle('../processed_data/ST14_processed.pkl')\n",
    "f_tmprss6 = pd.read_pickle('../processed_data/TMPRSS6_processed.pkl')\n",
    "f_klkb1 = pd.read_pickle('../processed_data/KLKB1_processed.pkl')\n",
    "fp_dark=np.load('../dumps/deprecated/DarkChemicalMatter_morgan_fingerprints.npz')\n",
    "fp_dark=fp_dark['fps']\n",
    "fp_tmprss11d = np.load('../dumps/deprecated/TMPRSS11D_morgan_fingerprints.npz')\n",
    "fp_st14 = np.load('../dumps/deprecated/ST14_morgan_fingerprints.npz')\n",
    "fp_tmprss6= np.load('../dumps/deprecated/TMPRSS6_morgan_fingerprints.npz')\n",
    "fp_klkb1=np.load('../dumps/deprecated/KLKB1_morgan_fingerprints.npz')\n",
    "fp_truth=np.load('../dumps/deprecated/TMPRSS2_morgan_fingerprints.npz')\n",
    "f_truth= f_truth.assign(cid= [int(lkey) for lkey in list(fp_truth.keys())]) #reassign 0 cids\n",
    "#TODO: use combined dataset for training with xcorr vals\n",
    "#method 1: try to concat all datasets together\n",
    "features=pd.concat([f_tmprss6, f_klkb1, f_st14, f_tmpss11d, f_truth]) #concat datasets in order of closeness to tmprss2, from Doug's analysis\n",
    "features.drop_duplicates(subset='cid', keep='last') #prioritize activity from tmprss2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(fp_dark.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head(5) #inspect data\n",
    "fps_merged = []\n",
    "ac_merged = []\n",
    "activity=[]\n",
    "cids=[]\n",
    "datalabels=[]\n",
    "#function to merge npz arrays\n",
    "def merge_keys(in_xarray, in_yarray, in_y2array, in_fp, in_data, in_cids,datalabel):\n",
    "     for i in range(len(in_fp.keys())):\n",
    "            if not int(list(in_fp.keys())[i]) in in_cids:\n",
    "                in_cids.append(int(list(in_fp.keys())[i]))\n",
    "                acval=in_data.loc[in_data['cid']==int(list(in_fp.keys())[i]), 'acvalue'].iloc[0]\n",
    "                active=in_data.loc[in_data['cid']==int(list(in_fp.keys())[i]), 'activity'].iloc[0]\n",
    "                in_yarray.append(acval)\n",
    "                in_xarray.append(in_fp[list(in_fp.keys())[i]])\n",
    "                if active == 'Active':\n",
    "                    in_y2array.append(1)\n",
    "                else:\n",
    "                    in_y2array.append(0)\n",
    "                datalabels.append(datalabel)\n",
    "     return in_xarray, in_yarray, in_y2array, in_cids, datalabels\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge in order of similarity\n",
    "fps_merged, ac_merged, activity,cids,datalabels=merge_keys(fps_merged, ac_merged, activity, fp_truth, features, cids,datalabel='tmprss2')\n",
    "fps_merged, ac_merged, activity,cids,datalabels=merge_keys(fps_merged, ac_merged, activity, fp_tmprss11d, features,cids,datalabel='tmprss11d')\n",
    "fps_merged, ac_merged, activity,cids,datalabels=merge_keys(fps_merged, ac_merged, activity, fp_st14, features,cids,datalabel='st14')\n",
    "fps_merged, ac_merged, activity,cids,datalabels=merge_keys(fps_merged, ac_merged, activity, fp_klkb1, features,cids,datalabel='klkb1')\n",
    "fps_merged, ac_merged, activity,cids,datalabels=merge_keys(fps_merged, ac_merged, activity, fp_tmprss6, features,cids, datalabel='tmprss6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to array\n",
    "fps_merged=np.array(fps_merged)\n",
    "activity=np.array(activity)\n",
    "ac_merged=np.array(ac_merged)\n",
    "ac_merged=-np.log10(ac_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test \n",
    "#half of tmprss2 active compounds to each set\n",
    "import random\n",
    "s=np.arange(len(list(fp_truth.keys())))\n",
    "random.shuffle(s)\n",
    "cut=41\n",
    "test=s[0:cut]\n",
    "train=s[cut::]\n",
    "\n",
    "#add dark data. here we generate 1 test set that includes only data from TMPRSS2 dataset + negative examples\n",
    "#and training data culled from all protein datasets, + negative examples that are not in the test set.\n",
    "#the samples from TMPRSS2, and negative examples are sampled randomly to be about 50 percent.\n",
    "s=np.arange(len(fp_dark))\n",
    "random.shuffle(s)\n",
    "cut=round(len(fp_dark)/2)\n",
    "test_dark=s[0:cut]\n",
    "train_dark=s[cut::]\n",
    "X_test=np.concatenate((fps_merged[test], fp_dark[test_dark]))\n",
    "X_train=np.concatenate((fps_merged[train], fps_merged[92::], fp_dark[train_dark]))\n",
    "y_train=np.concatenate((activity[train], activity[92::], np.zeros([len(train_dark)])))\n",
    "y2_train=np.concatenate((ac_merged[train], ac_merged[92::], np.zeros([len(train_dark)])))\n",
    "y_test=np.concatenate((activity[test], np.zeros([len(test_dark)])))\n",
    "y2_test=np.concatenate((ac_merged[test],np.zeros([len(test_dark)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#split training and test set, keep random_state to be an integer for reproducibility\n",
    "#train the forest (this can take a while)\n",
    "#in the example, about 2/3 go to training and 1/3 go to test\n",
    "#X_train, X_test, y_train, y_test = train_test_split(fps_merged,activity, test_size=0.33, random_state=39)\n",
    "rf=RandomForestClassifier(verbose=2, n_estimators=100, random_state=111)\n",
    "#rg=RandomForestRegressor(verbose=2, n_estimators=100, random_state=111)\n",
    "rf.fit(np.asarray(X_train), np.asarray(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(X_test)\n",
    "#print(y_pred)\n",
    "#show probabilities; print(rf.predict_proba(X_test))\n",
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the index of the features (of RDkit fingerprint) that were important\n",
    "importances = rf.feature_importances_\n",
    "featurenums = np.array([str(x).zfill(2) for x in range(len(importances))])\n",
    "indices = np.argsort(importances)[::-1][0:25]#get the 25 most important features\n",
    "plt.title('Feature Importances (train set)')\n",
    "plt.bar(range(len(indices)), importances[indices], align='center')\n",
    "plt.ylabel('Relative Importance')\n",
    "plt.xticks(range(len(indices)), featurenums[indices], rotation=90)\n",
    "plt.show()\n",
    "#output metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_array=np.isnan(y2_train)\n",
    "X_train2=X_train[~nan_array]\n",
    "y2_train2=y2_train[~nan_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now train the regressor, which is to predict the activity value itself\n",
    "#takes about 1 hour to run\n",
    "rg.fit(np.asarray(X_train2), np.asarray(y2_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reg=fps_merged[test]\n",
    "X_train_reg=np.concatenate((fps_merged[train], fps_merged[92::]))\n",
    "y2_train_reg=np.concatenate((ac_merged[train], ac_merged[92::]))\n",
    "y2_test_reg=ac_merged[test]\n",
    "nan_array=np.isnan(y2_train_reg)\n",
    "X_train_reg=X_train_reg[~nan_array]\n",
    "y2_train_reg=y2_train_reg[~nan_array]\n",
    "rg=RandomForestRegressor(verbose=2, n_estimators=50, random_state=111)\n",
    "rg.fit(np.asarray(X_train_reg), np.asarray(y2_train_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_regr=rg.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y2_test, y_pred_regr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_noneg=rg.predict(X_test_reg)\n",
    "print(r2_score(y2_test_reg, y_pred_reg_noneg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rg.feature_importances_\n",
    "featurenums = np.array([str(x).zfill(2) for x in range(len(importances))])\n",
    "indices = np.argsort(importances)[::-1][0:25]#get the 25 most important features\n",
    "plt.title('Feature Importances (train set)')\n",
    "plt.bar(range(len(indices)), importances[indices], align='center')\n",
    "plt.ylabel('Relative Importance')\n",
    "plt.xticks(range(len(indices)), featurenums[indices], rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with predictions and dates\n",
    "plt.plot(y2_test_reg, 'b.', label = 'actual')\n",
    "# Plot the predicted values\n",
    "plt.plot(y_pred_reg_noneg, 'ro', label = 'prediction')\n",
    "plt.xticks(rotation = '60'); \n",
    "\n",
    "# Graph labels\n",
    "plt.ylabel('activity value'); plt.title('Actual and Predicted Values');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "402px",
    "left": "823px",
    "right": "20px",
    "top": "75px",
    "width": "300px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
