{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the correlations between the various assay datasets to combine them into a \"tmprss2 equivalent\" dataset.  The algorithm goes like this:\n",
    "For each non-TMPRSS2 target:\n",
    "1. Find the set S of chemicals which were assayed against both TMPRSS2 and the target protein\n",
    "2. Manually remove outliers from S\n",
    "3. Calculate spearman_r correlations between log(TMPRSS2 activity) and log(target activity).  Outliers are manually removed by inspection.\n",
    "4. If spearman_r is high (>.70), perform a linear regression on S, x=TMPRSS2 activites, y=off-target activities.  Use the calculated slope to rescale the target's activity values.\n",
    "5. Construct combined dataset\n",
    "\n",
    "Combined Dataset Columns:\n",
    "\n",
    "* **acvalue_target**: The activity as measured in the original assay, i.e. activity on \"target\"\n",
    "* **active_target**: Whether acvalue_target is less than some threshold, defined in data processing notebooks (currently 50)\n",
    "* **target**: The protein the assay was conducted on (e.g. ST14, TMPRSS2)\n",
    "* **tmprss2_vs_target_spearman_r**: the spearman_r correlation from algorithm step 3\n",
    "* **acvalue_scaled_to_tmprss2**: rescaled activity value from algorithm step 4\n",
    "* **cid**: cid of compound\n",
    "* **smiles**: smiles of compound\n",
    "\n",
    "\n",
    "Note 1: spearman-r is used over pearson-r because our data has a skewed distribution.  See this article (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3576830/).  Note also that spearmanr(x, y) == spearmanr(log(x), log(y))\n",
    "\n",
    "Note 2: the reason I only adjust by slope and not also by intercept is because adjusting by intercept could result in negative activities, which don't make sense.  Fixing intercept at 0 would solve this, but does not seem to be a reasonable assumption.  A near-zero activity on an off-target protein doesn't necessarily mean a near-zero activity on TMPRSS2.  In practice, the correlated off-targets have intercepts near zero, so this is not worth worrying about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "from scipy import stats\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_colwidth', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect datasets\n",
    "def load_ds(ds_name):\n",
    "    return pd.read_pickle(f'../processed_data/{ds_name}_processed.pkl')\n",
    "TMPRSS2 = load_ds('TMPRSS2')\n",
    "\n",
    "off_targets = {ds_name: load_ds(ds_name) for ds_name in ['KLKB1', 'ST14', 'TMPRSS6', 'TMPRSS11D']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate overlaps\n",
    "overlaps = {}\n",
    "for name, off_target in off_targets.items():\n",
    "    overlaps[name] = pd.merge(TMPRSS2, off_target, on='cid')\n",
    "    print(f'{name}: num_overlaps={len(overlaps[name])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize the overlap correlations\n",
    "def visualize_overlaps(overlaps, square=False):\n",
    "    for name, overlap in overlaps.items():\n",
    "        plt.figure()\n",
    "        x = np.log(overlap['acvalue_x'])\n",
    "        y = np.log(overlap['acvalue_y'])\n",
    "        try:\n",
    "            sns.regplot(x, y, label=f'spearman_r: {spearmanr(x, y)[0]: .2f}')\n",
    "        except ValueError:\n",
    "            sns.regplot(x, y, label=f'spearman_r: undefined')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Log TMPRSS2 Activity Value')\n",
    "        plt.ylabel(f'Log {name} Activity Value')\n",
    "        plt.title(f'Correlation with {name}')\n",
    "        if square:\n",
    "            xlim = plt.gca().get_xlim()\n",
    "            ylim = plt.gca().get_ylim()\n",
    "            lim = [min(xlim[0], ylim[0]), max(xlim[1], ylim[1])]\n",
    "            plt.xlim(lim)\n",
    "            plt.ylim(lim)\n",
    "visualize_overlaps(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually drop outliers by inspection\n",
    "cleaned_overlaps = {}\n",
    "cleaned_overlaps['ST14'] = overlaps['ST14'][overlaps['ST14']['acvalue_x'] < .2]\n",
    "cleaned_overlaps['TMPRSS6'] = overlaps['TMPRSS6'][overlaps['TMPRSS6']['acvalue_x'] < .2]\n",
    "cleaned_overlaps['TMPRSS11D'] = overlaps['TMPRSS11D'][overlaps['TMPRSS11D']['acvalue_x'] < 7]\n",
    "\n",
    "visualize_overlaps(cleaned_overlaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summary of the off-targets:\n",
    "1. KLKB1 has insufficient data to determine correlation\n",
    "2. ST14 has a strong correlation with TMPRSS2\n",
    "3. TMPRSS6 has a strong correlation with TMPRSS2\n",
    "4. TMPRSS11D has no correlation with TMPRSS2\n",
    "\n",
    "We will thus only bother with scaling ST14 and TMPRSS6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: not only are there no overlaps between KLKB1 and TMPRSS2, there's no overlaps betwen KLKB1 and any of the other targets!  So we can't even try to do a transitive correlation.  See following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate overlaps between KLKB1 and other targets\n",
    "KLKB1_overlaps = {}\n",
    "for name, off_target in off_targets.items():\n",
    "    if name != 'KLKB1':\n",
    "        KLKB1_overlaps[name] = pd.merge(off_targets['KLKB1'], off_target, on='cid')\n",
    "        print(f'{name}: num_overlaps={len(KLKB1_overlaps[name])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "print('Before Scaling')\n",
    "visualize_overlaps({name: cleaned_overlaps[name] for name in ['ST14', 'TMPRSS6']}, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_slopes = {'KLKB1': np.nan, 'TMPRSS11D': np.nan}\n",
    "scaled_overlaps = {}\n",
    "for name in ['ST14', 'TMPRSS6']:\n",
    "    overlap = cleaned_overlaps[name].copy()\n",
    "    x = overlap['acvalue_x']\n",
    "    y = overlap['acvalue_y']\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "    regression_slopes[name] = slope\n",
    "    \n",
    "    scaled_overlaps[name] = overlap\n",
    "    scaled_overlaps[name]['acvalue_y'] /= slope\n",
    "print('After Scaling')\n",
    "visualize_overlaps(scaled_overlaps, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate spearman_rs\n",
    "spearman_rs = {}\n",
    "cleaned_overlaps\n",
    "for name, overlap in cleaned_overlaps.items():\n",
    "    spearman_rs[name] = spearmanr(overlap['acvalue_x'], overlap['acvalue_y'])[0]\n",
    "spearman_rs['KLKB1'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finally, construct the combined dataset\n",
    "orig_datasets = off_targets\n",
    "orig_datasets['TMPRSS2'] = TMPRSS2\n",
    "\n",
    "spearman_rs['TMPRSS2'] = 1\n",
    "regression_slopes['TMPRSS2'] = 1\n",
    "\n",
    "reformatted_datasets = []\n",
    "for target in ['TMPRSS2', 'KLKB1', 'ST14', 'TMPRSS6', 'TMPRSS11D']:\n",
    "    ds = orig_datasets[target].copy()\n",
    "    ds = ds.rename(columns={'acvalue': 'acvalue_target', 'activity': 'activity_target', 'morgan_fp': 'morgan_fingerprint'})\n",
    "    ds['target'] = target\n",
    "    ds['acvalue_scaled_to_tmprss2'] = ds['acvalue_target'] / regression_slopes[target]\n",
    "    ds['tmprss2_vs_target_spearman_r'] = spearman_rs[target]\n",
    "    reformatted_datasets.append(ds)\n",
    "\n",
    "combined_dataset = pd.concat(reformatted_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "combined_dataset = combined_dataset[['acvalue_target', 'activity_target', 'target', 'tmprss2_vs_target_spearman_r', 'acvalue_scaled_to_tmprss2', 'cid', 'morgan_fingerprint']]\n",
    "combined_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = combined_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file to disk\n",
    "combined_dataset.to_pickle('../processed_data/combined_dataset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: how to recover dataframe from saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = pd.read_pickle('../processed_data/combined_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# demonstration that fingerprint is loaded correctly\n",
    "print(\"Fingerprint type:\", type(df_loaded.morgan_fingerprint.iloc[0]))\n",
    "print(\"Fingerprint length:\", df_loaded.morgan_fingerprint.iloc[0].shape)\n",
    "print(\"First fingerprint equal:\", np.all(df_loaded.morgan_fingerprint.iloc[0] == combined_dataset.morgan_fingerprint.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tmprss2]",
   "language": "python",
   "name": "conda-env-tmprss2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
