{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"xsrf_cookies\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#load data labels and RDkit fingerprints\n",
    "#using pickled data\n",
    "with open('../dumps/combined_dataset.pkl', 'rb') as f:\n",
    "      data = pickle.load(f)\n",
    "\n",
    "N=len(data.loc[data['target'] == 'TMPRSS2']) #number of compounds tested against TMPRSS2 itself\n",
    "n_test=round(N/3) #withold for testing\n",
    "fp_dark=np.load('../dumps/DarkChemicalMatter_morgan_fingerprints.npz')\n",
    "fp_dark=fp_dark['fps']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to array\n",
    "#using merged data from pickle\n",
    "datalabels=list(data['target'])\n",
    "fps_merged=np.stack(data['morgan_fingerprint'])\n",
    "ac_merged_scaled=np.asarray(data['acvalue_scaled_to_tmprss2'])\n",
    "cids=list(data['cid'])\n",
    "act_list=list(data['activity_target'])\n",
    "activity_scaled=[]\n",
    "activity=[]\n",
    "for i in range(len(act_list)):\n",
    "    if act_list[i] == 'Active':\n",
    "        activity.append(1)\n",
    "    else:\n",
    "        activity.append(0)\n",
    "    if ac_merged_scaled[i]>0:\n",
    "        if act_list[i] == 'Active':\n",
    "            activity_scaled.append(1)\n",
    "        else:\n",
    "            activity_scaled.append(0)\n",
    "#alternatively\n",
    "ac_merged=np.asarray(data['acvalue_target'])\n",
    "#keep only the positive vals in ac_merged\n",
    "fps_merged_scaled=fps_merged[ac_merged_scaled>0]\n",
    "cids_scaled=[cid for i, cid in enumerate(cids) if ac_merged_scaled[i]>0]\n",
    "ac_merged_scaled=ac_merged[ac_merged_scaled>0]\n",
    "\n",
    "\n",
    "activity=np.array(activity)\n",
    "ac_merged=np.array(ac_merged)\n",
    "ac_merged=-np.log10(ac_merged)\n",
    "activity_scaled=np.array(activity_scaled)\n",
    "ac_merged_scaled=np.array(ac_merged_scaled)\n",
    "ac_merged_scaled=-np.log10(ac_merged_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test \n",
    "#half of tmprss2 active compounds to each set\n",
    "import random\n",
    "s=np.arange(N)\n",
    "random.shuffle(s)\n",
    "cut=n_test\n",
    "test=s[0:cut]\n",
    "train=s[cut::]\n",
    "\n",
    "#add dark data. here we generate 1 test set that includes only data from TMPRSS2 dataset + negative examples\n",
    "#and training data culled from all protein datasets, + negative examples that are not in the test set.\n",
    "#the samples from TMPRSS2, and negative examples are sampled randomly to be about 50 percent.\n",
    "s=np.arange(len(fp_dark))\n",
    "random.shuffle(s)\n",
    "cut=round(len(fp_dark)/2)\n",
    "test_dark=s[0:cut]\n",
    "train_dark=s[cut::]\n",
    "X_test=np.concatenate((fps_merged_scaled[test], fp_dark[test_dark]))\n",
    "X_train=np.concatenate((fps_merged_scaled[train], fps_merged_scaled[92::], fp_dark[train_dark]))\n",
    "y_train=np.concatenate((activity_scaled[train], activity_scaled[92::], np.zeros([len(train_dark)])))\n",
    "y2_train=np.concatenate((ac_merged_scaled[train], ac_merged_scaled[92::], np.zeros([len(train_dark)])))\n",
    "y_test=np.concatenate((activity_scaled[test], np.zeros([len(test_dark)])))\n",
    "y2_test=np.concatenate((ac_merged_scaled[test],np.zeros([len(test_dark)])))\n",
    "\n",
    "X_test_u=np.concatenate((fps_merged[test], fp_dark[test_dark]))\n",
    "X_train_u=np.concatenate((fps_merged[train], fps_merged[92::], fp_dark[train_dark]))\n",
    "y_train_u=np.concatenate((activity[train], activity[92::], np.zeros([len(train_dark)])))\n",
    "y2_train_u=np.concatenate((ac_merged[train], ac_merged[92::], np.zeros([len(train_dark)])))\n",
    "y_test_u=np.concatenate((activity[test], np.zeros([len(test_dark)])))\n",
    "y2_test_u=np.concatenate((ac_merged[test],np.zeros([len(test_dark)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate big training set\n",
    "X_train_all=np.concatenate((fps_merged_scaled, fp_dark))\n",
    "y2_train_all=np.concatenate((ac_merged_scaled, np.zeros([len(fp_dark)])))\n",
    "y_train_all=np.concatenate((activity_scaled, np.zeros([len(fp_dark)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#generate RF: classifier based on whether or not compound is thought to be active.\n",
    "#split training and test set, keep random_state to be an integer for reproducibility\n",
    "#train the forest (this can take a while)\n",
    "#in the example, about 2/3 go to training and 1/3 go to test\n",
    "#X_train, X_test, y_train, y_test = train_test_split(fps_merged,activity, test_size=0.33, random_state=39)\n",
    "rf=RandomForestClassifier(verbose=2, n_estimators=100, random_state=111)\n",
    "rf.fit(np.asarray(X_train), np.asarray(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(X_test)\n",
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the index of the features (of RDkit fingerprint) that were important\n",
    "importances = rf.feature_importances_\n",
    "featurenums = np.array([str(x).zfill(2) for x in range(len(importances))])\n",
    "indices = np.argsort(importances)[::-1][0:25]#get the 25 most important features\n",
    "plt.title('Feature Importances (train set)')\n",
    "plt.bar(range(len(indices)), importances[indices], align='center')\n",
    "plt.ylabel('Relative Importance')\n",
    "plt.xticks(range(len(indices)), featurenums[indices], rotation=90)\n",
    "plt.show()\n",
    "#output metrics\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RG, regressor with scaled activity values (drop zeros)\n",
    "#now train the regressor, which is to predict the activity value itself\n",
    "#takes about 1 hour to run\n",
    "rg_scaled=RandomForestRegressor(verbose=2, n_estimators=100, random_state=111)\n",
    "rg_scaled.fit(np.asarray(X_train), np.asarray(y2_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bloc for some hyperparameter tuning\n",
    "#to add stuff later\n",
    "from pprint import pprint\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rg_scaled.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RG_unsc, regressor with UNSCALED activity values\n",
    "#first drop nans\n",
    "nan_array=np.isnan(y2_train_u)\n",
    "X_train_u=X_train_u[~nan_array]\n",
    "y2_train_u=y2_train_u[~nan_array]\n",
    "rg=RandomForestRegressor(verbose=2, n_estimators=100, random_state=111)\n",
    "rg.fit(np.asarray(X_train_u), np.asarray(y2_train_u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reg=fps_merged[test]\n",
    "X_train_reg=np.concatenate((fps_merged[train], fps_merged[92::]))\n",
    "y2_train_reg=np.concatenate((ac_merged[train], ac_merged[92::]))\n",
    "y2_test_reg=ac_merged[test]\n",
    "nan_array=np.isnan(y2_train_reg)\n",
    "X_train_reg=X_train_reg[~nan_array]\n",
    "y2_train_reg=y2_train_reg[~nan_array]\n",
    "\n",
    "X_test_reg_scaled=fps_merged_scaled[test]\n",
    "X_train_reg_scaled=np.concatenate((fps_merged_scaled[train], fps_merged_scaled[92::]))\n",
    "y2_train_reg_scaled=np.concatenate((ac_merged_scaled[train], ac_merged_scaled[92::]))\n",
    "y2_test_reg_scaled=ac_merged_scaled[test]\n",
    "\n",
    "rg_pos_only=RandomForestRegressor(verbose=2, n_estimators=50, random_state=111)\n",
    "rg_pos_only_scaled=RandomForestRegressor(verbose=2, n_estimators=50, random_state=111)\n",
    "rg_pos_only.fit(np.asarray(X_train_reg), np.asarray(y2_train_reg))\n",
    "rg_pos_only_scaled.fit(np.asarray(X_train_reg_scaled), np.asarray(y2_train_reg_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "#scaled data, regression on all\n",
    "y_pred_regr=rg.predict(X_test_u)\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y2_test_u, y_pred_regr))\n",
    "\n",
    "#unscaled data, regression on all\n",
    "y_pred_regr_scaled=rg_scaled.predict(X_test)\n",
    "print(r2_score(y2_test, y_pred_regr_scaled))\n",
    "\n",
    "#scaled data, regression on positives\n",
    "y_pred_regr_pos=rg.predict(X_test_reg)\n",
    "print(r2_score(y2_test_reg, y_pred_regr_pos))\n",
    "\n",
    "#unscaled data, regression on positives\n",
    "y_pred_regr_scaled_pos=rg.predict(X_test_reg_scaled)\n",
    "print(r2_score(y2_test_reg_scaled, y_pred_regr_scaled_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_reg_noneg=rg.predict(X_test_reg)\n",
    "#print(r2_score(y2_test_reg, y_pred_reg_noneg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rg.feature_importances_\n",
    "featurenums = np.array([str(x).zfill(2) for x in range(len(importances))])\n",
    "indices = np.argsort(importances)[::-1][0:25]#get the 25 most important features\n",
    "plt.title('Feature Importances (train set)')\n",
    "plt.bar(range(len(indices)), importances[indices], align='center')\n",
    "plt.ylabel('Relative Importance')\n",
    "plt.xticks(range(len(indices)), featurenums[indices], rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with predictions and dates\n",
    "plt.plot(y2_test, 'b.', label = 'actual')\n",
    "# Plot the predicted values\n",
    "plt.plot(y_pred_regr, 'ro', label = 'prediction')\n",
    "plt.xticks(rotation = '60'); \n",
    "\n",
    "# Graph labels\n",
    "plt.ylabel('activity value'); plt.title('Actual and Predicted Values');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y2_test[y2_test>0], 'b.', label = 'actual')\n",
    "# Plot the predicted values\n",
    "plt.plot(y_pred_regr[y2_test>0], 'ro', label = 'prediction')\n",
    "plt.xticks(rotation = '60'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y2_test_reg, 'b.', label = 'actual')\n",
    "# Plot the predicted values\n",
    "plt.plot(y_pred_regr_pos, 'ro', label = 'prediction')\n",
    "plt.xticks(rotation = '60'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y2_test_reg_scaled, 'b.', label = 'actual')\n",
    "# Plot the predicted values\n",
    "plt.plot(y_pred_regr_scaled_pos, 'ro', label = 'prediction')\n",
    "plt.xticks(rotation = '60'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now fit everything\n",
    "rg_all=RandomForestRegressor(verbose=2, n_estimators=100, random_state=111)\n",
    "rg_all.fit(np.asarray(X_train_all), np.asarray(y2_train_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframe=np.load('../dumps/reframe_fp.npz')\n",
    "molnames=reframe['arr_1']\n",
    "reframe=reframe['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_activity=rg_all.predict(reframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(10**-(predicted_activity), 'ro', label = 'prediction')\n",
    "predicted_activity=10**-(predicted_activity)\n",
    "indices=np.argwhere(predicted_activity>=2)\n",
    "print(molnames[indices])\n",
    "print(predicted_activity[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_all2=RandomForestRegressor(verbose=2, n_estimators=100, random_state=111)\n",
    "rg_all2.fit(np.asarray(fps_merged_scaled), np.asarray(ac_merged_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_activity2=rg_all2.predict(reframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(10**-(predicted_activity2), 'ro', label = 'prediction')\n",
    "predicted_activity2=10**-(predicted_activity2)\n",
    "indices=np.argwhere(predicted_activity2>=5)\n",
    "print(molnames[indices])\n",
    "print(predicted_activity[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_array=np.isnan(ac_merged)\n",
    "fps_merged=fps_merged[~nan_array]\n",
    "ac_merged=ac_merged[~nan_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_all3=RandomForestRegressor(verbose=2, n_estimators=100, random_state=111)\n",
    "rg_all3.fit(np.asarray(fps_merged), np.asarray(ac_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_activity3=rg_all2.predict(reframe)\n",
    "plt.plot(10**-(predicted_activity3), 'ro', label = 'prediction')\n",
    "predicted_activity3=10**-(predicted_activity3)\n",
    "indices=np.argwhere(predicted_activity3>=5)\n",
    "print(molnames[indices])\n",
    "print(predicted_activity[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "402px",
    "left": "823px",
    "right": "20px",
    "top": "75px",
    "width": "300px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
